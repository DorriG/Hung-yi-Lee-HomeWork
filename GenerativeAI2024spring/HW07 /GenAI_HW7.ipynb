{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luoclab/Hung-yi-Lee-HomeWork/blob/main/GenerativeAI2024spring/HW07%20/GenAI_HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 7 - Understand what Generative AI is thinking"
      ],
      "metadata": {
        "id": "UFOUfh2k1jFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#直接安装inseq,不要安装其他的包了，否则会有环境错误\n",
        "!pip install -q inseq"
      ],
      "metadata": {
        "id": "OJ4XUXW3n-Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这是我成功运行所有代码的当时包的版本\n",
        "# !pip list\n",
        "#inseq   0.6.0\n",
        "#Package                            Version\n",
        "# numpy                              1.26.4\n",
        "# torch                              2.5.1+cu124\n",
        "# transformers                       4.48.3"
      ],
      "metadata": {
        "id": "ow3hmOxGo1Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inseq"
      ],
      "metadata": {
        "id": "QfcXohN2qEsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ElcWXfA8o3n"
      },
      "source": [
        "## Machine Translation Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e8MpYJ9LgBy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# List of attribution methods to be used\n",
        "attribution_methods = ['saliency', 'attention']\n",
        "\n",
        "\n",
        "print(f\"======= Attribution Method: {attribution_methods[0]} =======\")\n",
        "# Load the Chinese-to-English translation model and set up the attribution method\n",
        "model = inseq.load_model(\"Helsinki-NLP/opus-mt-zh-en\", attribution_methods[0])\n",
        "\n",
        "# Apply attribution to the input text using the specified method\n",
        "attribution_result = model.attribute(\n",
        "    input_texts=\"我喜歡機器學習和人工智慧。\",\n",
        "    step_scores=[\"probability\"],\n",
        ")\n",
        "\n",
        "# Remove '▁' from the tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "for attr in attribution_result.sequence_attributions:\n",
        "    for item in attr.source:\n",
        "        item.token = item.token.replace('▁', '')\n",
        "    for item in attr.target:\n",
        "        item.token = item.token.replace('▁', '')\n",
        "\n",
        "# Display the attribution results\n",
        "attribution_result.show()\n",
        "\n",
        "print(f\"======= Attribution Method: {attribution_methods[1]} =======\")\n",
        "# Load the Chinese-to-English translation model and set up the attribution method\n",
        "model = inseq.load_model(\"Helsinki-NLP/opus-mt-zh-en\", attribution_methods[1])\n",
        "\n",
        "# Apply attribution to the input text using the specified method\n",
        "attribution_result = model.attribute(\n",
        "    input_texts=\"我喜歡機器學習和人工智慧。\",\n",
        "    # step_scores=[\"probability\"],\n",
        ")\n",
        "\n",
        "# Remove '▁' from the tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "for attr in attribution_result.sequence_attributions:\n",
        "    for item in attr.source:\n",
        "        item.token = item.token.replace('▁', '')\n",
        "    for item in attr.target:\n",
        "        item.token = item.token.replace('▁', '')\n",
        "\n",
        "# Display the attribution results\n",
        "attribution_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lgZR0CJ-7xs"
      },
      "source": [
        "## Sentence Completion Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ650ekw5jo-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\", load_in_8bit=True, device_map=\"auto\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\", device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for method in attribution_methods:\n",
        "# Load the model with the specified attribution method\n",
        "inseq_model = inseq.load_model(model, attribution_methods[0])\n",
        "\n",
        "# Apply attribution to the input text using the specified method\n",
        "attribution_result = inseq_model.attribute(\n",
        "    input_texts=\"The first president of America is\",\n",
        "    step_scores=[\"probability\"],\n",
        ")\n",
        "\n",
        "# Remove 'Ġ' from GPT2's BPE tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "for attr in attribution_result.sequence_attributions:\n",
        "    for item in attr.source:\n",
        "        item.token = item.token.replace('Ġ', '')\n",
        "    for item in attr.target:\n",
        "        item.token = item.token.replace('Ġ', '')\n",
        "\n",
        "# Display the attribution results\n",
        "attribution_result.show()\n",
        "\n",
        "inseq_model = inseq.load_model(model, attribution_methods[1])\n",
        "\n",
        "# Apply attribution to the input text using the specified method\n",
        "attribution_result = inseq_model.attribute(\n",
        "    input_texts=\"The first president of America is\",\n",
        "    # step_scores=[\"probability\"],\n",
        ")\n",
        "\n",
        "# Remove 'Ġ' from GPT2's BPE tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "for attr in attribution_result.sequence_attributions:\n",
        "    for item in attr.source:\n",
        "        item.token = item.token.replace('Ġ', '')\n",
        "    for item in attr.target:\n",
        "        item.token = item.token.replace('Ġ', '')\n",
        "\n",
        "# Display the attribution results\n",
        "attribution_result.show()"
      ],
      "metadata": {
        "id": "8Nfr55IvSCuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pyh50g-4Q1ZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}